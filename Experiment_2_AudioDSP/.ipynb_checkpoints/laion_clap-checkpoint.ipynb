{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from laion_clap import CLAP_Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Utility Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2norm(x, axis=-1, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Apply L2 normalization to vectors along a given axis.\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (norm + eps)\n",
    "\n",
    "def spearman_corr(x, y):\n",
    "    rx = pd.Series(x).rank(method=\"average\").to_numpy()\n",
    "    ry = pd.Series(y).rank(method=\"average\").to_numpy()\n",
    "    if np.std(rx) < 1e-12 or np.std(ry) < 1e-12:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(rx, ry)[0,1])\n",
    "\n",
    "AUDIO_EXT = \".wav\"\n",
    "\n",
    "# Generic regex that matches any <stem>_<type>_<desc>_<scale>.wav\n",
    "GENERIC_AUDIO_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_(?P<type>eq|reverb|rvb)_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1(?:\\.0)?)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_audio_files(audio_dir: str, valid_types=None, audio_ext=\".wav\") -> pd.DataFrame:\n",
    "    if not os.path.isdir(audio_dir):\n",
    "        raise FileNotFoundError(f\"❌ Directory does not exist: {audio_dir}\")\n",
    "\n",
    "    if valid_types is not None:\n",
    "        valid_types = set(t.lower() for t in valid_types)\n",
    "\n",
    "    rows = []\n",
    "    for root, _, files in os.walk(audio_dir):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() != audio_ext:\n",
    "                continue\n",
    "            m = GENERIC_AUDIO_RE.match(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            file_type = m.group(\"type\").lower()\n",
    "            if valid_types and file_type not in valid_types:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"path\": os.path.join(root, f),\n",
    "                \"type\": file_type,\n",
    "                \"stem\": m.group(\"stem\"),\n",
    "                \"descriptor\": m.group(\"desc\").lower(),\n",
    "                \"scale\": float(m.group(\"scale\"))\n",
    "            })\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"⚠️ No matching files found in: {audio_dir}\")\n",
    "        return pd.DataFrame(columns=[\"path\", \"type\", \"stem\", \"descriptor\", \"scale\"])\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values([\"type\", \"descriptor\", \"scale\", \"path\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def classify_trend(df_desc):\n",
    "    \"\"\"\n",
    "    Classify the trend of delta_target values across scale levels.\n",
    "\n",
    "    Returns:\n",
    "        str: Trend type (monotonic or peak location)\n",
    "    \"\"\"\n",
    "    g = df_desc.set_index(\"scale\").reindex(EXPECTED_SCALES)\n",
    "    if g[\"delta_target\"].isna().any():\n",
    "        return \"Insufficient data\"\n",
    "\n",
    "    d0, d1, d2 = g[\"delta_target\"].tolist()\n",
    "\n",
    "    # Check monotonicity (with tolerance)\n",
    "    if d0 <= d1 + EPS and d1 <= d2 + EPS:\n",
    "        return \"Monotonic up\"\n",
    "    if d0 >= d1 - EPS and d1 >= d2 - EPS:\n",
    "        return \"Monotonic down\"\n",
    "\n",
    "    # Identify peak location\n",
    "    peak_idx = int(np.argmax([d0, d1, d2]))\n",
    "    return {0: \"Peak low (0.3)\", 1: \"Peak mid (0.6)\", 2: \"Peak high (1.0)\"}[peak_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EQ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of EQ descriptors used in filenames and CLAP embeddings\n",
    "EQ_DESCRIPTORS = [\n",
    "    'warm', 'cold', 'soft', 'loud', 'bright', 'soothing', 'harsh', 'heavy', 'cool',\n",
    "    'smooth', 'calm', 'clear', 'tinny', 'sharp', 'hard', 'crisp', 'mellow', 'dark',\n",
    "    'peaceful', 'gentle'\n",
    "]\n",
    "\n",
    "# === PATHS ===\n",
    "# NOTE: Replace these with actual file paths when running\n",
    "EQ_DIR = \"/Users/lindseydeng/Desktop/Timbre_Study/timbre_semantics_experiment2/test_audio/eq_audio\"   # Directory containing EQ-modified audio files\n",
    "EQ_ORIGINAL_PATH =  \"/Users/lindseydeng/Desktop/Timbre_Study/timbre_semantics_experiment2/test_audio/guitar.wav\"  # Path to the original unmodified audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Model & Text Embeddings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load our best checkpoint in the paper.\n",
      "The checkpoint is already downloaded\n",
      "Load Checkpoint...\n",
      "logit_scale_a \t Loaded\n",
      "logit_scale_t \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_real.weight \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_imag.weight \t Loaded\n",
      "audio_branch.logmel_extractor.melW \t Loaded\n",
      "audio_branch.bn0.weight \t Loaded\n",
      "audio_branch.bn0.bias \t Loaded\n",
      "audio_branch.patch_embed.proj.weight \t Loaded\n",
      "audio_branch.patch_embed.proj.bias \t Loaded\n",
      "audio_branch.patch_embed.norm.weight \t Loaded\n",
      "audio_branch.patch_embed.norm.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.norm.weight \t Loaded\n",
      "audio_branch.norm.bias \t Loaded\n",
      "audio_branch.tscam_conv.weight \t Loaded\n",
      "audio_branch.tscam_conv.bias \t Loaded\n",
      "audio_branch.head.weight \t Loaded\n",
      "audio_branch.head.bias \t Loaded\n",
      "text_branch.embeddings.word_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.position_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.token_type_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.bias \t Loaded\n",
      "text_branch.pooler.dense.weight \t Loaded\n",
      "text_branch.pooler.dense.bias \t Loaded\n",
      "text_transform.sequential.0.weight \t Loaded\n",
      "text_transform.sequential.0.bias \t Loaded\n",
      "text_transform.sequential.3.weight \t Loaded\n",
      "text_transform.sequential.3.bias \t Loaded\n",
      "text_projection.0.weight \t Loaded\n",
      "text_projection.0.bias \t Loaded\n",
      "text_projection.2.weight \t Loaded\n",
      "text_projection.2.bias \t Loaded\n",
      "audio_transform.sequential.0.weight \t Loaded\n",
      "audio_transform.sequential.0.bias \t Loaded\n",
      "audio_transform.sequential.3.weight \t Loaded\n",
      "audio_transform.sequential.3.bias \t Loaded\n",
      "audio_projection.0.weight \t Loaded\n",
      "audio_projection.0.bias \t Loaded\n",
      "audio_projection.2.weight \t Loaded\n",
      "audio_projection.2.bias \t Loaded\n"
     ]
    }
   ],
   "source": [
    "laion_eq = CLAP_Module(enable_fusion=False)\n",
    "laion_eq.load_ckpt()  # Load default pretrained checkpoint\n",
    "laion_eq.eval()\n",
    "\n",
    "EQ_TEXT_LABELS = EQ_DESCRIPTORS\n",
    "EQ_TEXT_EMBS = laion_eq.get_text_embedding(EQ_TEXT_LABELS, use_tensor=False)  # Shape: [M, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Parse Audio Files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path type    stem descriptor  \\\n",
      "0  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar     bright   \n",
      "1  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar     bright   \n",
      "2  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar     bright   \n",
      "3  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar       calm   \n",
      "4  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar       calm   \n",
      "5  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar       calm   \n",
      "6  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar      clear   \n",
      "7  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar      clear   \n",
      "8  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar      clear   \n",
      "9  /Users/lindseydeng/Desktop/Timbre_Study/timbre...   eq  guitar       cold   \n",
      "\n",
      "   scale  \n",
      "0    0.3  \n",
      "1    0.6  \n",
      "2    1.0  \n",
      "3    0.3  \n",
      "4    0.6  \n",
      "5    1.0  \n",
      "6    0.3  \n",
      "7    0.6  \n",
      "8    1.0  \n",
      "9    0.3  \n",
      "✅ Total files found: 60\n"
     ]
    }
   ],
   "source": [
    "AUDIO_EXT = \".wav\"\n",
    "EQ_FNAME_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_eq_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1\\.0|1)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "eq_files_df = parse_audio_files(EQ_DIR, valid_types=[\"eq\"])\n",
    "print(eq_files_df.head(10))\n",
    "print(f\"✅ Total files found: {len(eq_files_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Embed Audio***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio embeddings: shape = [1 + N, D]\n",
    "eq_audio_paths = [EQ_ORIGINAL_PATH] + eq_files_df[\"path\"].tolist()\n",
    "eq_audio_embs = laion_eq.get_audio_embedding_from_filelist(x=eq_audio_paths, use_tensor=False)\n",
    "\n",
    "# Split original and manipulated embeddings\n",
    "eq_orig_emb = eq_audio_embs[0:1, :]     # Shape: [1, D]\n",
    "eq_manip_embs = eq_audio_embs[1:, :]    # Shape: [N, D]\n",
    "\n",
    "# Normalize all embeddings (L2 norm)\n",
    "A_orig = l2norm(eq_orig_emb)\n",
    "A_manip = l2norm(eq_manip_embs)\n",
    "T = l2norm(EQ_TEXT_EMBS)  # Text embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Compute Similarity Delta***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>stem</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>scale</th>\n",
       "      <th>sim_target</th>\n",
       "      <th>sim_orig_target</th>\n",
       "      <th>delta_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>bright</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>-0.023624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>bright</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.026693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>bright</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.073276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>-0.004644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.015216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>calm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.044759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.005885</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>0.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>0.050488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>clear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111233</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>0.126556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>cold</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.084302</td>\n",
       "      <td>-0.070721</td>\n",
       "      <td>-0.013581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>cold</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.064946</td>\n",
       "      <td>-0.070721</td>\n",
       "      <td>0.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "      <td>cold</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.085681</td>\n",
       "      <td>-0.070721</td>\n",
       "      <td>-0.014960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path    stem descriptor  \\\n",
       "0   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar     bright   \n",
       "1   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar     bright   \n",
       "2   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar     bright   \n",
       "3   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       calm   \n",
       "4   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       calm   \n",
       "5   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       calm   \n",
       "6   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar      clear   \n",
       "7   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar      clear   \n",
       "8   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar      clear   \n",
       "9   /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       cold   \n",
       "10  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       cold   \n",
       "11  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar       cold   \n",
       "\n",
       "    scale  sim_target  sim_orig_target  delta_target  \n",
       "0     0.3   -0.037304        -0.013680     -0.023624  \n",
       "1     0.6    0.013013        -0.013680      0.026693  \n",
       "2     1.0    0.059596        -0.013680      0.073276  \n",
       "3     0.3    0.000181         0.004824     -0.004644  \n",
       "4     0.6    0.020040         0.004824      0.015216  \n",
       "5     1.0    0.049583         0.004824      0.044759  \n",
       "6     0.3   -0.005885        -0.015323      0.009438  \n",
       "7     0.6    0.035166        -0.015323      0.050488  \n",
       "8     1.0    0.111233        -0.015323      0.126556  \n",
       "9     0.3   -0.084302        -0.070721     -0.013581  \n",
       "10    0.6   -0.064946        -0.070721      0.005775  \n",
       "11    1.0   -0.085681        -0.070721     -0.014960  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original audio similarity to each text descriptor → [M]\n",
    "eq_orig_sims = (A_orig @ T.T)[0]\n",
    "\n",
    "# Manipulated audio similarity to each descriptor → [N, M]\n",
    "eq_manip_sims = A_manip @ T.T\n",
    "\n",
    "# Map descriptor name to index in the text embedding matrix\n",
    "eq_desc2idx = {desc: i for i, desc in enumerate(EQ_TEXT_LABELS)}\n",
    "\n",
    "rows = []\n",
    "for i, row in eq_files_df.iterrows():\n",
    "    desc = row[\"descriptor\"]\n",
    "    idx = eq_desc2idx[desc]\n",
    "    \n",
    "    s_target = float(eq_manip_sims[i, idx])      # Similarity of manipulated audio\n",
    "    s_orig_target = float(eq_orig_sims[idx])     # Similarity of original audio\n",
    "\n",
    "    rows.append({\n",
    "        \"path\": row[\"path\"],\n",
    "        \"stem\": row[\"stem\"],\n",
    "        \"descriptor\": desc,\n",
    "        \"scale\": float(row[\"scale\"]),\n",
    "        \"sim_target\": s_target,\n",
    "        \"sim_orig_target\": s_orig_target,\n",
    "        \"delta_target\": s_target - s_orig_target\n",
    "    })\n",
    "\n",
    "# Final DataFrame of results\n",
    "laion_eq_target_df = pd.DataFrame(rows).sort_values([\"descriptor\", \"scale\"]).reset_index(drop=True)\n",
    "laion_eq_target_df.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aggregate Metrics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean delta_target by scale\n",
    "laion_eq_overall = (\n",
    "    laion_eq_target_df\n",
    "    .groupby(\"scale\")[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"scale\")\n",
    ")\n",
    "\n",
    "# Mean delta_target by descriptor and scale\n",
    "laion_eq_by_desc = (\n",
    "    laion_eq_target_df\n",
    "    .groupby([\"descriptor\", \"scale\"])[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values([\"descriptor\", \"scale\"])\n",
    ")\n",
    "\n",
    "laion_eq_overall, laion_eq_by_desc.head(10)\n",
    "\n",
    "# Save to CSV\n",
    "OUT = \"./outputs/LAION_CLAP\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "laion_eq_overall.to_csv(f\"{OUT}/laionclap_eq_mean_delta_by_scale.csv\", index=False)\n",
    "laion_eq_by_desc.to_csv(f\"{OUT}/laionclap_eq_delta_by_descriptor_and_scale.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descriptor</th>\n",
       "      <th>trend_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warm</td>\n",
       "      <td>Monotonic down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gentle</td>\n",
       "      <td>Monotonic down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smooth</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sharp</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mellow</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loud</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heavy</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>harsh</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crisp</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cool</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clear</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hard</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cold</td>\n",
       "      <td>Peak high (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>soothing</td>\n",
       "      <td>Peak high (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tinny</td>\n",
       "      <td>Peak low (0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>calm</td>\n",
       "      <td>Peak low (0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dark</td>\n",
       "      <td>Peak mid (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>soft</td>\n",
       "      <td>Peak mid (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bright</td>\n",
       "      <td>Peak mid (0.6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   descriptor       trend_type\n",
       "0        warm   Monotonic down\n",
       "1      gentle   Monotonic down\n",
       "2      smooth     Monotonic up\n",
       "3       sharp     Monotonic up\n",
       "4    peaceful     Monotonic up\n",
       "5      mellow     Monotonic up\n",
       "6        loud     Monotonic up\n",
       "7       heavy     Monotonic up\n",
       "8       harsh     Monotonic up\n",
       "9       crisp     Monotonic up\n",
       "10       cool     Monotonic up\n",
       "11      clear     Monotonic up\n",
       "12       hard     Monotonic up\n",
       "13       cold  Peak high (1.0)\n",
       "14   soothing  Peak high (1.0)\n",
       "15      tinny   Peak low (0.3)\n",
       "16       calm   Peak low (0.3)\n",
       "17       dark   Peak mid (0.6)\n",
       "18       soft   Peak mid (0.6)\n",
       "19     bright   Peak mid (0.6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "trend_type\n",
       "Monotonic up       11\n",
       "Peak mid (0.6)      3\n",
       "Monotonic down      2\n",
       "Peak high (1.0)     2\n",
       "Peak low (0.3)      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#trend analysis\n",
    "\n",
    "EXPECTED_SCALES = [0.3, 0.6, 1.0]\n",
    "EPS = 1e-6 \n",
    "\n",
    "# Apply trend classification per descriptor\n",
    "trend_rows = []\n",
    "for desc, group in laion_eq_target_df.groupby(\"descriptor\", as_index=False):\n",
    "    trend = classify_trend(group[[\"scale\", \"delta_target\"]].copy())\n",
    "    trend_rows.append({\"descriptor\": desc, \"trend_type\": trend})\n",
    "\n",
    "# Final trend classification DataFrame\n",
    "laion_trend_df = pd.DataFrame(trend_rows).sort_values(\"trend_type\").reset_index(drop=True)\n",
    "display(laion_trend_df)\n",
    "\n",
    "# Count occurrences of each trend type\n",
    "laion_trend_counts = laion_trend_df[\"trend_type\"].value_counts()\n",
    "display(laion_trend_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>scale</th>\n",
       "      <th>sim_target</th>\n",
       "      <th>sim_orig_target</th>\n",
       "      <th>delta_target</th>\n",
       "      <th>path</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>bright</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>-0.023624</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>bright</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.026693</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>bright</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>0.073276</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>-0.004644</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>calm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>/Users/lindseydeng/Desktop/Timbre_Study/timbre...</td>\n",
       "      <td>guitar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model descriptor  scale  sim_target  sim_orig_target  delta_target  \\\n",
       "0  LAION-CLAP     bright    0.3   -0.037304        -0.013680     -0.023624   \n",
       "1  LAION-CLAP     bright    0.6    0.013013        -0.013680      0.026693   \n",
       "2  LAION-CLAP     bright    1.0    0.059596        -0.013680      0.073276   \n",
       "3  LAION-CLAP       calm    0.3    0.000181         0.004824     -0.004644   \n",
       "4  LAION-CLAP       calm    0.6    0.020040         0.004824      0.015216   \n",
       "5  LAION-CLAP       calm    1.0    0.049583         0.004824      0.044759   \n",
       "\n",
       "                                                path    stem  \n",
       "0  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  \n",
       "1  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  \n",
       "2  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  \n",
       "3  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  \n",
       "4  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  \n",
       "5  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  guitar  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>trend_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>bright</td>\n",
       "      <td>Peak mid (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>calm</td>\n",
       "      <td>Peak low (0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>clear</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>cold</td>\n",
       "      <td>Peak high (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>cool</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAION-CLAP</td>\n",
       "      <td>crisp</td>\n",
       "      <td>Monotonic up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model descriptor       trend_type\n",
       "19  LAION-CLAP     bright   Peak mid (0.6)\n",
       "16  LAION-CLAP       calm   Peak low (0.3)\n",
       "11  LAION-CLAP      clear     Monotonic up\n",
       "13  LAION-CLAP       cold  Peak high (1.0)\n",
       "10  LAION-CLAP       cool     Monotonic up\n",
       "9   LAION-CLAP      crisp     Monotonic up"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OUTPUT DIRECTORY ===\n",
    "\n",
    "OUT = \"./outputs/LAION_CLAP\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# PREPARE TARGETS DATAFRAME \n",
    "\n",
    "laion_eq_targets = laion_eq_target_df.copy()\n",
    "laion_eq_targets[\"model\"] = \"LAION-CLAP\"\n",
    "laion_eq_targets = laion_eq_targets[\n",
    "    [\"model\", \"descriptor\", \"scale\", \"sim_target\", \"sim_orig_target\", \"delta_target\", \"path\", \"stem\"]\n",
    "].sort_values([\"descriptor\", \"scale\", \"path\"])\n",
    "\n",
    "#PREPARE TRENDS DATAFRAME\n",
    "\n",
    "laion_eq_trends = laion_trend_df.copy()\n",
    "laion_eq_trends[\"model\"] = \"LAION-CLAP\"\n",
    "laion_eq_trends = laion_eq_trends[[\"model\", \"descriptor\", \"trend_type\"]].sort_values(\"descriptor\")\n",
    "\n",
    "#SAVE MAIN RESULTS\n",
    "\n",
    "laion_eq_targets.to_csv(f\"{OUT}/laionclap_eq_targets.csv\", index=False)\n",
    "laion_eq_trends.to_csv(f\"{OUT}/laionclap_eq_trends.csv\", index=False)\n",
    "\n",
    "display(laion_eq_targets.head(6))\n",
    "display(laion_eq_trends.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RVB_DESCRIPTORS = [\n",
    "    'echo', 'distant', 'warm', 'spacious', 'loud', 'deep', \n",
    "    'muffled', 'church', 'big', 'distorted', 'hollow', 'sad', 'soft', \n",
    "    'bass', 'strong', 'low', 'haunting', 'clear', 'tinny', 'hall'\n",
    "]\n",
    "\n",
    "# === PATHS ===\n",
    "RVB_DIR = \"/Users/lindseydeng/Desktop/Timbre_Study/timbre_semantics_experiment2/test_audio/reverb\"   # NOTE: Replace these with actual file paths when running\n",
    "RVB_ORIGINAL_PATH = \"/Users/lindseydeng/Desktop/Timbre_Study/timbre_semantics_experiment2/test_audio/guitar.wav\"   # Path to the original unmodified audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Model & Text Embeddings (Reverb)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load our best checkpoint in the paper.\n",
      "The checkpoint is already downloaded\n",
      "Load Checkpoint...\n",
      "logit_scale_a \t Loaded\n",
      "logit_scale_t \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_real.weight \t Loaded\n",
      "audio_branch.spectrogram_extractor.stft.conv_imag.weight \t Loaded\n",
      "audio_branch.logmel_extractor.melW \t Loaded\n",
      "audio_branch.bn0.weight \t Loaded\n",
      "audio_branch.bn0.bias \t Loaded\n",
      "audio_branch.patch_embed.proj.weight \t Loaded\n",
      "audio_branch.patch_embed.proj.bias \t Loaded\n",
      "audio_branch.patch_embed.norm.weight \t Loaded\n",
      "audio_branch.patch_embed.norm.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.0.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.0.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.0.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.1.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.1.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.1.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.2.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.3.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.4.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.norm2.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.2.blocks.5.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.2.downsample.reduction.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.weight \t Loaded\n",
      "audio_branch.layers.2.downsample.norm.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.0.mlp.fc2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.relative_position_bias_table \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.qkv.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.attn.proj.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.norm2.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc1.bias \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.weight \t Loaded\n",
      "audio_branch.layers.3.blocks.1.mlp.fc2.bias \t Loaded\n",
      "audio_branch.norm.weight \t Loaded\n",
      "audio_branch.norm.bias \t Loaded\n",
      "audio_branch.tscam_conv.weight \t Loaded\n",
      "audio_branch.tscam_conv.bias \t Loaded\n",
      "audio_branch.head.weight \t Loaded\n",
      "audio_branch.head.bias \t Loaded\n",
      "text_branch.embeddings.word_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.position_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.token_type_embeddings.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.weight \t Loaded\n",
      "text_branch.embeddings.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.0.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.1.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.2.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.3.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.4.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.5.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.6.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.7.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.8.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.9.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.10.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.query.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.key.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.self.value.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.attention.output.LayerNorm.bias \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.intermediate.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.dense.bias \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.weight \t Loaded\n",
      "text_branch.encoder.layer.11.output.LayerNorm.bias \t Loaded\n",
      "text_branch.pooler.dense.weight \t Loaded\n",
      "text_branch.pooler.dense.bias \t Loaded\n",
      "text_transform.sequential.0.weight \t Loaded\n",
      "text_transform.sequential.0.bias \t Loaded\n",
      "text_transform.sequential.3.weight \t Loaded\n",
      "text_transform.sequential.3.bias \t Loaded\n",
      "text_projection.0.weight \t Loaded\n",
      "text_projection.0.bias \t Loaded\n",
      "text_projection.2.weight \t Loaded\n",
      "text_projection.2.bias \t Loaded\n",
      "audio_transform.sequential.0.weight \t Loaded\n",
      "audio_transform.sequential.0.bias \t Loaded\n",
      "audio_transform.sequential.3.weight \t Loaded\n",
      "audio_transform.sequential.3.bias \t Loaded\n",
      "audio_projection.0.weight \t Loaded\n",
      "audio_projection.0.bias \t Loaded\n",
      "audio_projection.2.weight \t Loaded\n",
      "audio_projection.2.bias \t Loaded\n"
     ]
    }
   ],
   "source": [
    "laion_rvb = CLAP_Module(enable_fusion=False)\n",
    "laion_rvb.load_ckpt()\n",
    "laion_rvb.eval()\n",
    "\n",
    "\n",
    "RVB_TEXT_LABELS = RVB_DESCRIPTORS\n",
    "RVB_TEXT_EMBS = laion_rvb.get_text_embedding(RVB_TEXT_LABELS, use_tensor=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RVB_DIR is: /Users/lindseydeng/Desktop/Timbre_Study/timbre_semantics_experiment2/test_audio/reverb\n",
      "Found 60 .wav files\n",
      "- guitar_reverb_deep_0.6.wav\n",
      "- guitar_reverb_strong_0.3.wav\n",
      "- guitar_reverb_big_0.6.wav\n",
      "- guitar_reverb_warm_0.6.wav\n",
      "- guitar_reverb_spacious_0.6.wav\n",
      "- guitar_reverb_haunting_0.3.wav\n",
      "- guitar_reverb_spacious_0.3.wav\n",
      "- guitar_reverb_sad_1.0.wav\n",
      "- guitar_reverb_haunting_0.6.wav\n",
      "- guitar_reverb_hollow_1.0.wav\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "print(\"RVB_DIR is:\", RVB_DIR)\n",
    "files = glob.glob(os.path.join(RVB_DIR, \"**/*.wav\"), recursive=True)\n",
    "print(f\"Found {len(files)} .wav files\")\n",
    "for f in files[:10]:\n",
    "    print(\"-\", os.path.basename(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Parse Audio Files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                path    type    stem  \\\n",
       " 0  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 1  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 2  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 3  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 4  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 5  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 6  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 7  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 8  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " 9  /Users/lindseydeng/Desktop/Timbre_Study/timbre...  reverb  guitar   \n",
       " \n",
       "   descriptor  scale  \n",
       " 0       bass    0.3  \n",
       " 1       bass    0.6  \n",
       " 2       bass    1.0  \n",
       " 3        big    0.3  \n",
       " 4        big    0.6  \n",
       " 5        big    1.0  \n",
       " 6     church    0.3  \n",
       " 7     church    0.6  \n",
       " 8     church    1.0  \n",
       " 9      clear    0.3  ,\n",
       " 60)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvb_files_df = parse_audio_files(RVB_DIR, valid_types=[\"reverb\", \"rvb\"])\n",
    "rvb_files_df.head(10), len(rvb_files_df)\n",
    "#rvb_audio_paths = [RVB_ORIGINAL_PATH] + rvb_files_df[\"path\"].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Embed Audio***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvb_audio_embs = laion_rvb.get_audio_embedding_from_filelist(x=rvb_audio_paths, use_tensor=False)  # [1+N, D]\n",
    "rvb_orig_emb = rvb_audio_embs[0:1, :]     # [1, D]\n",
    "rvb_manip_embs = rvb_audio_embs[1:, :]    # [N, D]\n",
    "rvb_manip_embs.shape, rvb_orig_emb.shape\n",
    "\n",
    "# Normalize\n",
    "A_orig = l2norm(rvb_orig_emb)          # [1, D]\n",
    "A_manip = l2norm(rvb_manip_embs)       # [N, D]\n",
    "T = l2norm(RVB_TEXT_EMBS)              # [M, D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Compute Similarity***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original audio similarity to each text descriptor → [M]\n",
    "rvb_orig_sims = (A_orig @ T.T)[0]\n",
    "\n",
    "# Manipulated audio similarity to each descriptor → [N, M]\n",
    "rvb_manip_sims = A_manip @ T.T\n",
    "\n",
    "# Map descriptor name to index in the text embedding matrix\n",
    "rvb_desc2idx = {d:i for i, d in enumerate(RVB_TEXT_LABELS)}\n",
    "rows = []\n",
    "for i, r in rvb_files_df.iterrows():\n",
    "    desc = r[\"descriptor\"]\n",
    "    idx = rvb_desc2idx[desc]\n",
    "    s_target = float(rvb_manip_sims[i, idx])\n",
    "    s_orig_target = float(rvb_orig_sims[idx])\n",
    "    rows.append({\n",
    "        \"path\": r[\"path\"],\n",
    "        \"stem\": r[\"stem\"],\n",
    "        \"descriptor\": desc,\n",
    "        \"scale\": float(r[\"scale\"]),\n",
    "        \"sim_target\": s_target,           # cosine(sim) in [-1, 1]\n",
    "        \"sim_orig_target\": s_orig_target,\n",
    "        \"delta_target\": s_target - s_orig_target\n",
    "    })\n",
    "\n",
    "laion_rvb_target_df = pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\"]).reset_index(drop=True)\n",
    "laion_rvb_target_df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aggregate Metrices***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laion_rvb_overall = (\n",
    "    laion_rvb_target_df.groupby(\"scale\")[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"scale\")\n",
    ")\n",
    "laion_rvb_by_desc = (\n",
    "    laion_rvb_target_df.groupby([\"descriptor\",\"scale\"])[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values([\"descriptor\",\"scale\"])\n",
    ")\n",
    "\n",
    "laion_rvb_overall, laion_rvb_by_desc.head(10)\n",
    "\n",
    "OUT = \"./outputs/LAION_CLAP\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "laion_rvb_overall.to_csv(f\"{OUT}/laionclap_rvb_mean_delta_by_scale.csv\", index=False)\n",
    "laion_rvb_by_desc.to_csv(f\"{OUT}/laionclap_rvb_delta_by_descriptor_and_scale.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
