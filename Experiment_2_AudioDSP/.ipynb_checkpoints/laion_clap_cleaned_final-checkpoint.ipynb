{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174a932d",
   "metadata": {},
   "source": [
    "# LAION-CLAP Audio Embedding Analysis\n",
    "\n",
    "This notebook performs preprocessing, embedding, and analysis for audio data using LAION-CLAP. Refactored for clarity, modularity, and open-sourcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "EQ_DESCRIPTORS = ['bass', 'mid', 'treble']  # Example descriptors\n",
    "\n",
    "# === Audio File Configuration ===\n",
    "AUDIO_EXT = \".wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Utility Functions ===\n",
    "\n",
    "def load_audio_file(filepath, target_sr=48000):\n",
    "    waveform, sr = torchaudio.load(filepath)\n",
    "    if sr != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(sr, target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "    return waveform\n",
    "\n",
    "def compute_embeddings(model, waveform):\n",
    "    with torch.no_grad():\n",
    "        return model.get_audio_embedding_from_data(x=waveform, use_tensor=True)\n",
    "\n",
    "def summarize_embeddings(df, group_by='label'):\n",
    "    return df.groupby(group_by).mean().reset_index()\n",
    "\n",
    "def parse_filename(filename, pattern):\n",
    "    match = pattern.match(filename)\n",
    "    return match.groups() if match else (None,) * len(pattern.groupindex)\n",
    "\n",
    "def collect_audio_files(root_dir, ext=\".wav\"):\n",
    "    return [str(p) for p in pathlib.Path(root_dir).rglob(f\"*{ext}\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab77fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Loading ===\n",
    "# === CONFIG (EQ only, LAION-CLAP) ===\n",
    "EQ_DESCRIPTORS = [\n",
    "    'warm','cold','soft','loud','bright','soothing','harsh','heavy','cool',\n",
    "    'smooth','calm','clear','tinny','sharp','hard','crisp','mellow','dark',\n",
    "    'peaceful','gentle'\n",
    "]\n",
    "\n",
    "EQ_DIR = \"/Users/lindseydeng/Desktop/timbre_semantics_experiment2/test_audio/eq_audio\"  # folder with guitar_eq_<desc>_<scale>.wav\n",
    "EQ_ORIGINAL_PATH = \"/Users/lindseydeng/Desktop/timbre_semantics_experiment2/test_audio/guitar.wav\"\n",
    "\n",
    "\n",
    "import os, re, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from laion_clap import CLAP_Module\n",
    "\n",
    "\n",
    "laion_eq = CLAP_Module(enable_fusion=False)\n",
    "laion_eq.load_ckpt()  # default pretrained\n",
    "laion_eq.eval()\n",
    "\n",
    "\n",
    "AUDIO_EXT = \".wav\"\n",
    "EQ_FNAME_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_eq_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1\\.0|1)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def list_eq_files(eq_dir: str):\n",
    "    rows = []\n",
    "    for root, _, files in os.walk(eq_dir):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() != AUDIO_EXT:\n",
    "                continue\n",
    "            m = EQ_FNAME_RE.match(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"path\": os.path.join(root, f),\n",
    "                \"stem\": m.group(\"stem\"),\n",
    "                \"descriptor\": m.group(\"desc\").lower(),\n",
    "                \"scale\": float(m.group(\"scale\"))\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\",\"path\"]).reset_index(drop=True)\n",
    "\n",
    "eq_files_df = list_eq_files(EQ_DIR)\n",
    "eq_files_df.head(10), len(eq_files_df)\n",
    "\n",
    "\n",
    "# Build path list with original first (helps compute deltas)\n",
    "eq_audio_paths = [EQ_ORIGINAL_PATH] + eq_files_df[\"path\"].tolist()\n",
    "\n",
    "# Get embeddings as numpy (use_tensor=False)\n",
    "eq_audio_embs = laion_eq.get_audio_embedding_from_filelist(x=eq_audio_paths, use_tensor=False)  # [1+N, D]\n",
    "eq_orig_emb = eq_audio_embs[0:1, :]     # [1, D]\n",
    "eq_manip_embs = eq_audio_embs[1:, :]    # [N, D]\n",
    "eq_manip_embs.shape, eq_orig_emb.shape\n",
    "\n",
    "\n",
    "import os, re, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from laion_clap import CLAP_Module\n",
    "\n",
    "# === CONFIG ===\n",
    "RVB_DESCRIPTORS = [\n",
    "  'echo', 'distant', 'warm', 'spacious', 'loud', 'deep', \n",
    "    'muffled', 'church', 'big', 'distorted', 'hollow', 'sad', 'soft', \n",
    "    'bass', 'strong', 'low', 'haunting', 'clear','tinny', 'hall']\n",
    "\n",
    "RVB_DIR = \"//Users/lindseydeng/Desktop/timbre_semantics_experiment2/test_audio/reverb\"  # folder with guitar_eq_<desc>_<scale>.wav\n",
    "RVB_ORIGINAL_PATH = \"/Users/lindseydeng/Desktop/timbre_semantics_experiment2/test_audio/guitar.wav\"\n",
    "\n",
    "laion_rvb = CLAP_Module(enable_fusion=False)\n",
    "laion_rvb.load_ckpt()  # default pretrained\n",
    "laion_rvb.eval()\n",
    "\n",
    "\n",
    "AUDIO_EXT = \".wav\"\n",
    "RVB_FNAME_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_reverb_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1\\.0|1)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def list_rvb_files(rvb_dir: str):\n",
    "    rows = []\n",
    "    for root, _, files in os.walk(rvb_dir):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() != AUDIO_EXT:\n",
    "                continue\n",
    "            m = RVB_FNAME_RE.match(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"path\": os.path.join(root, f),\n",
    "                \"stem\": m.group(\"stem\"),\n",
    "                \"descriptor\": m.group(\"desc\").lower(),\n",
    "                \"scale\": float(m.group(\"scale\"))\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\",\"path\"]).reset_index(drop=True)\n",
    "\n",
    "rvb_files_df = list_rvb_files(RVB_DIR)\n",
    "rvb_files_df.head(10), len(rvb_files_df)\n",
    "\n",
    "rvb_audio_paths = [RVB_ORIGINAL_PATH] + rvb_files_df[\"path\"].tolist()\n",
    "\n",
    "# Get embeddings as numpy (use_tensor=False)\n",
    "rvb_audio_embs = laion_rvb.get_audio_embedding_from_filelist(x=rvb_audio_paths, use_tensor=False)  # [1+N, D]\n",
    "rvb_orig_emb = rvb_audio_embs[0:1, :]     # [1, D]\n",
    "rvb_manip_embs = rvb_audio_embs[1:, :]    # [N, D]\n",
    "rvb_manip_embs.shape, rvb_orig_emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Embedding Audio ===\n",
    "# Build path list with original first (helps compute deltas)\n",
    "eq_audio_paths = [EQ_ORIGINAL_PATH] + eq_files_df[\"path\"].tolist()\n",
    "\n",
    "# Get embeddings as numpy (use_tensor=False)\n",
    "eq_audio_embs = laion_eq.get_audio_embedding_from_filelist(x=eq_audio_paths, use_tensor=False)  # [1+N, D]\n",
    "eq_orig_emb = eq_audio_embs[0:1, :]     # [1, D]\n",
    "eq_manip_embs = eq_audio_embs[1:, :]    # [N, D]\n",
    "eq_manip_embs.shape, eq_orig_emb.shape\n",
    "\n",
    "\n",
    "rvb_audio_paths = [RVB_ORIGINAL_PATH] + rvb_files_df[\"path\"].tolist()\n",
    "\n",
    "# Get embeddings as numpy (use_tensor=False)\n",
    "rvb_audio_embs = laion_rvb.get_audio_embedding_from_filelist(x=rvb_audio_paths, use_tensor=False)  # [1+N, D]\n",
    "rvb_orig_emb = rvb_audio_embs[0:1, :]     # [1, D]\n",
    "rvb_manip_embs = rvb_audio_embs[1:, :]    # [N, D]\n",
    "rvb_manip_embs.shape, rvb_orig_emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Postprocessing & Analysis ===\n",
    "AUDIO_EXT = \".wav\"\n",
    "EQ_FNAME_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_eq_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1\\.0|1)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def list_eq_files(eq_dir: str):\n",
    "    rows = []\n",
    "    for root, _, files in os.walk(eq_dir):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() != AUDIO_EXT:\n",
    "                continue\n",
    "            m = EQ_FNAME_RE.match(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"path\": os.path.join(root, f),\n",
    "                \"stem\": m.group(\"stem\"),\n",
    "                \"descriptor\": m.group(\"desc\").lower(),\n",
    "                \"scale\": float(m.group(\"scale\"))\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\",\"path\"]).reset_index(drop=True)\n",
    "\n",
    "eq_files_df = list_eq_files(EQ_DIR)\n",
    "eq_files_df.head(10), len(eq_files_df)\n",
    "\n",
    "\n",
    "def l2norm(x, axis=-1, eps=1e-12):\n",
    "    n = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (n + eps)\n",
    "\n",
    "# Normalize\n",
    "A_orig = l2norm(eq_orig_emb)          # [1, D]\n",
    "A_manip = l2norm(eq_manip_embs)       # [N, D]\n",
    "T = l2norm(EQ_TEXT_EMBS)              # [M, D]\n",
    "\n",
    "# Cosine similarities\n",
    "# original vs all descriptors -> [M]\n",
    "eq_orig_sims = (A_orig @ T.T)[0]\n",
    "\n",
    "# manipulated vs all descriptors -> [N, M]\n",
    "eq_manip_sims = A_manip @ T.T\n",
    "\n",
    "# Map descriptor -> column index\n",
    "eq_desc2idx = {d:i for i, d in enumerate(EQ_TEXT_LABELS)}\n",
    "\n",
    "# Build tidy table: sim_target, sim_orig_target, delta_target\n",
    "rows = []\n",
    "for i, r in eq_files_df.iterrows():\n",
    "    desc = r[\"descriptor\"]\n",
    "    idx = eq_desc2idx[desc]\n",
    "    s_target = float(eq_manip_sims[i, idx])\n",
    "    s_orig_target = float(eq_orig_sims[idx])\n",
    "    rows.append({\n",
    "        \"path\": r[\"path\"],\n",
    "        \"stem\": r[\"stem\"],\n",
    "        \"descriptor\": desc,\n",
    "        \"scale\": float(r[\"scale\"]),\n",
    "        \"sim_target\": s_target,           # cosine(sim) in [-1, 1]\n",
    "        \"sim_orig_target\": s_orig_target,\n",
    "        \"delta_target\": s_target - s_orig_target\n",
    "    })\n",
    "\n",
    "laion_eq_target_df = pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\"]).reset_index(drop=True)\n",
    "laion_eq_target_df.head(12)\n",
    "\n",
    "\n",
    "laion_eq_overall = (\n",
    "    laion_eq_target_df.groupby(\"scale\")[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"scale\")\n",
    ")\n",
    "laion_eq_by_desc = (\n",
    "    laion_eq_target_df.groupby([\"descriptor\",\"scale\"])[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values([\"descriptor\",\"scale\"])\n",
    ")\n",
    "\n",
    "laion_eq_overall, laion_eq_by_desc.head(60)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EXPECTED_SCALES = [0.3, 0.6, 1.0]\n",
    "EPS = 1e-6  \n",
    "\n",
    "def classify_trend(df_desc):\n",
    "    g = df_desc.set_index(\"scale\").reindex(EXPECTED_SCALES)\n",
    "    if g[\"delta_target\"].isna().any():\n",
    "        return \"Insufficient data\"\n",
    "    d0, d1, d2 = g[\"delta_target\"].tolist()\n",
    "\n",
    "    # monotonic checks with tolerance\n",
    "    if d0 <= d1 + EPS and d1 <= d2 + EPS:\n",
    "        return \"Monotonic up\"\n",
    "    if d0 >= d1 - EPS and d1 >= d2 - EPS:\n",
    "        return \"Monotonic down\"\n",
    "\n",
    "    # peak location\n",
    "    deltas = [d0, d1, d2]\n",
    "    peak_idx = int(np.argmax(deltas))\n",
    "    return {0: \"Peak low (0.3)\", 1: \"Peak mid (0.6)\", 2: \"Peak high (1.0)\"}[peak_idx]\n",
    "\n",
    "# build trend table\n",
    "trend_rows = []\n",
    "for desc, g in laion_eq_target_df.groupby(\"descriptor\", as_index=False):\n",
    "    trend = classify_trend(g[[\"scale\",\"delta_target\"]].copy())\n",
    "    trend_rows.append({\"descriptor\": desc, \"trend_type\": trend})\n",
    "\n",
    "laion_trend_df = pd.DataFrame(trend_rows).sort_values(\"trend_type\").reset_index(drop=True)\n",
    "display(laion_trend_df)\n",
    "\n",
    "# quick counts\n",
    "laion_trend_counts = laion_trend_df[\"trend_type\"].value_counts()\n",
    "display(laion_trend_counts)\n",
    "\n",
    "\n",
    "if \"laion_eq_overall\" not in globals():\n",
    "    laion_eq_overall = (\n",
    "        laion_eq_target_df.groupby(\"scale\")[\"delta_target\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values(\"scale\")\n",
    "    )\n",
    "\n",
    "if \"laion_eq_by_desc\" not in globals():\n",
    "    laion_eq_by_desc = (\n",
    "        laion_eq_target_df.groupby([\"descriptor\",\"scale\"])[\"delta_target\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values([\"descriptor\",\"scale\"])\n",
    "    )\n",
    "\n",
    "if \"laion_trend_counts\" not in globals():\n",
    "    laion_trend_counts = (\n",
    "        laion_eq_trends.groupby(\"trend_type\")\n",
    "        .size()\n",
    "        .rename(\"count\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "\n",
    "display(laion_eq_overall)\n",
    "display(laion_eq_by_desc.head(20))\n",
    "display(laion_trend_counts)\n",
    "\n",
    "# Save CSVs\n",
    "laion_eq_overall.to_csv(f\"{OUT}/laionclap_eq_mean_delta_by_scale.csv\", index=False)\n",
    "laion_eq_by_desc.to_csv(f\"{OUT}/laionclap_eq_delta_by_descriptor_and_scale.csv\", index=False)\n",
    "laion_trend_counts.to_csv(f\"{OUT}/laionclap_eq_trend_counts.csv\", index=False)\n",
    "\n",
    "\n",
    "def spearman_corr(x, y):\n",
    "    rx = pd.Series(x).rank(method=\"average\").to_numpy()\n",
    "    ry = pd.Series(y).rank(method=\"average\").to_numpy()\n",
    "    if np.std(rx) < 1e-12 or np.std(ry) < 1e-12:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(rx, ry)[0,1])\n",
    "\n",
    "rows = []\n",
    "for desc, g in laion_eq_targets.groupby(\"descriptor\"):\n",
    "    g = g.sort_values(\"scale\")\n",
    "    if g[\"scale\"].nunique() >= 3:   # expect 0.3, 0.6, 1.0\n",
    "        rho = spearman_corr(g[\"scale\"].to_numpy(), g[\"delta_target\"].to_numpy())\n",
    "    else:\n",
    "        rho = np.nan\n",
    "    rows.append({\"descriptor\": desc, \"spearman_delta_vs_scale\": rho})\n",
    "\n",
    "laion_eq_spearman = pd.DataFrame(rows).sort_values(\"spearman_delta_vs_scale\", ascending=False)\n",
    "display(laion_eq_spearman.head(10))\n",
    "display(laion_eq_spearman.tail(10))\n",
    "\n",
    "laion_eq_spearman.to_csv(f\"{OUT}/laionclap_eq_spearman_delta_vs_scale.csv\", index=False)\n",
    "\n",
    "\n",
    "AUDIO_EXT = \".wav\"\n",
    "RVB_FNAME_RE = re.compile(\n",
    "    r\"^(?P<stem>.+?)_reverb_(?P<desc>[A-Za-z0-9\\-]+)_(?P<scale>0\\.\\d+|1\\.0|1)\\.wav$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def list_rvb_files(rvb_dir: str):\n",
    "    rows = []\n",
    "    for root, _, files in os.walk(rvb_dir):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() != AUDIO_EXT:\n",
    "                continue\n",
    "            m = RVB_FNAME_RE.match(f)\n",
    "            if not m:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"path\": os.path.join(root, f),\n",
    "                \"stem\": m.group(\"stem\"),\n",
    "                \"descriptor\": m.group(\"desc\").lower(),\n",
    "                \"scale\": float(m.group(\"scale\"))\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\",\"path\"]).reset_index(drop=True)\n",
    "\n",
    "rvb_files_df = list_rvb_files(RVB_DIR)\n",
    "rvb_files_df.head(10), len(rvb_files_df)\n",
    "\n",
    "def l2norm(x, axis=-1, eps=1e-12):\n",
    "    n = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (n + eps)\n",
    "\n",
    "# Normalize\n",
    "A_orig = l2norm(rvb_orig_emb)          # [1, D]\n",
    "A_manip = l2norm(rvb_manip_embs)       # [N, D]\n",
    "T = l2norm(RVB_TEXT_EMBS)              # [M, D]\n",
    "\n",
    "# Cosine similarities\n",
    "# original vs all descriptors -> [M]\n",
    "rvb_orig_sims = (A_orig @ T.T)[0]\n",
    "\n",
    "# manipulated vs all descriptors -> [N, M]\n",
    "rvb_manip_sims = A_manip @ T.T\n",
    "\n",
    "# Map descriptor -> column index\n",
    "rvb_desc2idx = {d:i for i, d in enumerate(RVB_TEXT_LABELS)}\n",
    "# Build tidy table: sim_target, sim_orig_target, delta_target\n",
    "rows = []\n",
    "for i, r in rvb_files_df.iterrows():\n",
    "    desc = r[\"descriptor\"]\n",
    "    idx = rvb_desc2idx[desc]\n",
    "    s_target = float(rvb_manip_sims[i, idx])\n",
    "    s_orig_target = float(rvb_orig_sims[idx])\n",
    "    rows.append({\n",
    "        \"path\": r[\"path\"],\n",
    "        \"stem\": r[\"stem\"],\n",
    "        \"descriptor\": desc,\n",
    "        \"scale\": float(r[\"scale\"]),\n",
    "        \"sim_target\": s_target,           # cosine(sim) in [-1, 1]\n",
    "        \"sim_orig_target\": s_orig_target,\n",
    "        \"delta_target\": s_target - s_orig_target\n",
    "    })\n",
    "\n",
    "laion_rvb_target_df = pd.DataFrame(rows).sort_values([\"descriptor\",\"scale\"]).reset_index(drop=True)\n",
    "laion_rvb_target_df.head(12)\n",
    "\n",
    "\n",
    "\n",
    "laion_rvb_overall = (\n",
    "    laion_rvb_target_df.groupby(\"scale\")[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"scale\")\n",
    ")\n",
    "laion_rvb_by_desc = (\n",
    "    laion_rvb_target_df.groupby([\"descriptor\",\"scale\"])[\"delta_target\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values([\"descriptor\",\"scale\"])\n",
    ")\n",
    "\n",
    "laion_rvb_overall, laion_rvb_by_desc.head(60)\n",
    "\n",
    "\n",
    "EXPECTED_SCALES = [0.3, 0.6, 1.0]\n",
    "EPS = 1e-6  \n",
    "\n",
    "def classify_trend(df_desc):\n",
    "    g = df_desc.set_index(\"scale\").reindex(EXPECTED_SCALES)\n",
    "    if g[\"delta_target\"].isna().any():\n",
    "        return \"Insufficient data\"\n",
    "    d0, d1, d2 = g[\"delta_target\"].tolist()\n",
    "\n",
    "    # monotonic checks with tolerance\n",
    "    if d0 <= d1 + EPS and d1 <= d2 + EPS:\n",
    "        return \"Monotonic up\"\n",
    "    if d0 >= d1 - EPS and d1 >= d2 - EPS:\n",
    "        return \"Monotonic down\"\n",
    "\n",
    "    # peak location\n",
    "    deltas = [d0, d1, d2]\n",
    "    peak_idx = int(np.argmax(deltas))\n",
    "    return {0: \"Peak low (0.3)\", 1: \"Peak mid (0.6)\", 2: \"Peak high (1.0)\"}[peak_idx]\n",
    "\n",
    "# build trend table\n",
    "trend_rows = []\n",
    "for desc, g in laion_rvb_target_df.groupby(\"descriptor\", as_index=False):\n",
    "    trend = classify_trend(g[[\"scale\",\"delta_target\"]].copy())\n",
    "    trend_rows.append({\"descriptor\": desc, \"trend_type\": trend})\n",
    "\n",
    "laion_trend_df = pd.DataFrame(trend_rows).sort_values(\"trend_type\").reset_index(drop=True)\n",
    "display(laion_trend_df)\n",
    "\n",
    "# quick counts\n",
    "laion_trend_counts = laion_trend_df[\"trend_type\"].value_counts()\n",
    "display(laion_trend_counts)\n",
    "\n",
    "\n",
    "if \"laion_rvb_overall\" not in globals():\n",
    "    laion_rvb_overall = (\n",
    "        laion_rvb_target_df.groupby(\"scale\")[\"delta_target\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values(\"scale\")\n",
    "    )\n",
    "\n",
    "if \"laion_rvb_by_desc\" not in globals():\n",
    "    laion_rvb_by_desc = (\n",
    "        laion_rvb_target_df.groupby([\"descriptor\",\"scale\"])[\"delta_target\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values([\"descriptor\",\"scale\"])\n",
    "    )\n",
    "\n",
    "if \"laion_trend_counts\" not in globals():\n",
    "    laion_trend_counts = (\n",
    "        laion_rvb_trends.groupby(\"trend_type\")\n",
    "        .size()\n",
    "        .rename(\"count\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "\n",
    "display(laion_rvb_overall)\n",
    "display(laion_rvb_by_desc.head(20))\n",
    "display(laion_trend_counts)\n",
    "\n",
    "# Save CSVs\n",
    "laion_rvb_overall.to_csv(f\"{OUT}/laionclap_rvb_mean_delta_by_scale.csv\", index=False)\n",
    "laion_rvb_by_desc.to_csv(f\"{OUT}/laionclap_rvb_delta_by_descriptor_and_scale.csv\", index=False)\n",
    "laion_trend_counts.to_csv(f\"{OUT}/laionclap_rvb_trend_counts.csv\", index=False)\n",
    "\n",
    "\n",
    "def spearman_corr(x, y):\n",
    "    rx = pd.Series(x).rank(method=\"average\").to_numpy()\n",
    "    ry = pd.Series(y).rank(method=\"average\").to_numpy()\n",
    "    if np.std(rx) < 1e-12 or np.std(ry) < 1e-12:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(rx, ry)[0,1])\n",
    "\n",
    "\n",
    "rows = []\n",
    "for desc, g in laion_rvb_targets.groupby(\"descriptor\"):\n",
    "    g = g.sort_values(\"scale\")\n",
    "    if g[\"scale\"].nunique() >= 3:   # expect 0.3, 0.6, 1.0\n",
    "        rho = spearman_corr(g[\"scale\"].to_numpy(), g[\"delta_target\"].to_numpy())\n",
    "    else:\n",
    "        rho = np.nan\n",
    "    rows.append({\"descriptor\": desc, \"spearman_delta_vs_scale\": rho})\n",
    "\n",
    "laion_rvb_spearman = pd.DataFrame(rows).sort_values(\"spearman_delta_vs_scale\", ascending=False)\n",
    "display(laion_rvb_spearman.head(10))\n",
    "display(laion_rvb_spearman.tail(10))\n",
    "\n",
    "laion_rvb_spearman.to_csv(f\"{OUT}/laionclap_rvb_spearman_delta_vs_scale.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
